/* eslint-disable */
// @generated by protobuf-ts 2.9.3 with parameter long_type_number,use_proto_field_name,ts_nocheck,eslint_disable
// @generated from protobuf file "onnx.proto3" (package "onnx", syntax proto3)
// tslint:disable
// @ts-nocheck
//
//
// WARNING: This file is automatically generated!  Please edit onnx.in.proto.
//
//
//
// SPDX-License-Identifier: Apache-2.0
//
import { MessageType } from "@protobuf-ts/runtime";
/**
 * Attributes
 *
 * A named attribute containing either singular float, integer, string, graph,
 * and tensor values, or repeated float, integer, string, graph, and tensor values.
 * An AttributeProto MUST contain the name field, and *only one* of the
 * following content fields, effectively enforcing a C/C++ union equivalent.
 *
 * @generated from protobuf message onnx.AttributeProto
 */
export interface AttributeProto {
    /**
     * The name field MUST be present for this version of the IR.
     *
     * @generated from protobuf field: string name = 1;
     */
    name: string; // namespace Attribute
    /**
     * if ref_attr_name is not empty, ref_attr_name is the attribute name in parent function.
     * In this case, this AttributeProto does not contain data, and it's a reference of attribute
     * in parent scope.
     * NOTE: This should ONLY be used in function (sub-graph). It's invalid to be used in main graph.
     *
     * @generated from protobuf field: string ref_attr_name = 21;
     */
    ref_attr_name: string;
    /**
     * A human-readable documentation for this attribute. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 13;
     */
    doc_string: string;
    /**
     * The type field MUST be present for this version of the IR.
     * For 0.0.1 versions of the IR, this field was not defined, and
     * implementations needed to use has_field heuristics to determine
     * which value field was in use.  For IR_VERSION 0.0.2 or later, this
     * field MUST be set and match the f|i|s|t|... field in use.  This
     * change was made to accommodate proto3 implementations.
     *
     * @generated from protobuf field: onnx.AttributeProto.AttributeType type = 20;
     */
    type: AttributeProto_AttributeType; // discriminator that indicates which field below is in use
    /**
     * Exactly ONE of the following fields must be present for this version of the IR
     *
     * @generated from protobuf field: float f = 2;
     */
    f: number; // float
    /**
     * @generated from protobuf field: int64 i = 3;
     */
    i: number; // int
    /**
     * @generated from protobuf field: bytes s = 4;
     */
    s: Uint8Array; // UTF-8 string
    /**
     * @generated from protobuf field: onnx.TensorProto t = 5;
     */
    t?: TensorProto; // tensor value
    /**
     * @generated from protobuf field: onnx.GraphProto g = 6;
     */
    g?: GraphProto; // graph
    /**
     * @generated from protobuf field: onnx.SparseTensorProto sparse_tensor = 22;
     */
    sparse_tensor?: SparseTensorProto; // sparse tensor value
    /**
     * Do not use field below, it's deprecated.
     * optional ValueProto v = 12;         // value - subsumes everything but graph
     *
     * @generated from protobuf field: onnx.TypeProto tp = 14;
     */
    tp?: TypeProto; // type proto
    /**
     * @generated from protobuf field: repeated float floats = 7;
     */
    floats: number[]; // list of floats
    /**
     * @generated from protobuf field: repeated int64 ints = 8;
     */
    ints: number[]; // list of ints
    /**
     * @generated from protobuf field: repeated bytes strings = 9;
     */
    strings: Uint8Array[]; // list of UTF-8 strings
    /**
     * @generated from protobuf field: repeated onnx.TensorProto tensors = 10;
     */
    tensors: TensorProto[]; // list of tensors
    /**
     * @generated from protobuf field: repeated onnx.GraphProto graphs = 11;
     */
    graphs: GraphProto[]; // list of graph
    /**
     * @generated from protobuf field: repeated onnx.SparseTensorProto sparse_tensors = 23;
     */
    sparse_tensors: SparseTensorProto[]; // list of sparse tensors
    /**
     * @generated from protobuf field: repeated onnx.TypeProto type_protos = 15;
     */
    type_protos: TypeProto[]; // list of type protos
}
/**
 * Note: this enum is structurally identical to the OpSchema::AttrType
 * enum defined in schema.h.  If you rev one, you likely need to rev the other.
 *
 * @generated from protobuf enum onnx.AttributeProto.AttributeType
 */
export enum AttributeProto_AttributeType {
    /**
     * @generated from protobuf enum value: UNDEFINED = 0;
     */
    UNDEFINED = 0,
    /**
     * @generated from protobuf enum value: FLOAT = 1;
     */
    FLOAT = 1,
    /**
     * @generated from protobuf enum value: INT = 2;
     */
    INT = 2,
    /**
     * @generated from protobuf enum value: STRING = 3;
     */
    STRING = 3,
    /**
     * @generated from protobuf enum value: TENSOR = 4;
     */
    TENSOR = 4,
    /**
     * @generated from protobuf enum value: GRAPH = 5;
     */
    GRAPH = 5,
    /**
     * @generated from protobuf enum value: SPARSE_TENSOR = 11;
     */
    SPARSE_TENSOR = 11,
    /**
     * @generated from protobuf enum value: TYPE_PROTO = 13;
     */
    TYPE_PROTO = 13,
    /**
     * @generated from protobuf enum value: FLOATS = 6;
     */
    FLOATS = 6,
    /**
     * @generated from protobuf enum value: INTS = 7;
     */
    INTS = 7,
    /**
     * @generated from protobuf enum value: STRINGS = 8;
     */
    STRINGS = 8,
    /**
     * @generated from protobuf enum value: TENSORS = 9;
     */
    TENSORS = 9,
    /**
     * @generated from protobuf enum value: GRAPHS = 10;
     */
    GRAPHS = 10,
    /**
     * @generated from protobuf enum value: SPARSE_TENSORS = 12;
     */
    SPARSE_TENSORS = 12,
    /**
     * @generated from protobuf enum value: TYPE_PROTOS = 14;
     */
    TYPE_PROTOS = 14
}
/**
 * Defines information on value, including the name, the type, and
 * the shape of the value.
 *
 * @generated from protobuf message onnx.ValueInfoProto
 */
export interface ValueInfoProto {
    /**
     * This field MUST be present in this version of the IR.
     *
     * @generated from protobuf field: string name = 1;
     */
    name: string; // namespace Value
    /**
     * This field MUST be present in this version of the IR for
     * inputs and outputs of the top-level graph.
     *
     * @generated from protobuf field: onnx.TypeProto type = 2;
     */
    type?: TypeProto;
    /**
     * A human-readable documentation for this value. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 3;
     */
    doc_string: string;
}
/**
 * Nodes
 *
 * Computation graphs are made up of a DAG of nodes, which represent what is
 * commonly called a "layer" or "pipeline stage" in machine learning frameworks.
 *
 * For example, it can be a node of type "Conv" that takes in an image, a filter
 * tensor and a bias tensor, and produces the convolved output.
 *
 * @generated from protobuf message onnx.NodeProto
 */
export interface NodeProto {
    /**
     * @generated from protobuf field: repeated string input = 1;
     */
    input: string[]; // namespace Value
    /**
     * @generated from protobuf field: repeated string output = 2;
     */
    output: string[]; // namespace Value
    /**
     * An optional identifier for this node in a graph.
     * This field MAY be absent in ths version of the IR.
     *
     * @generated from protobuf field: string name = 3;
     */
    name: string; // namespace Node
    /**
     * The symbolic identifier of the Operator to execute.
     *
     * @generated from protobuf field: string op_type = 4;
     */
    op_type: string; // namespace Operator
    /**
     * The domain of the OperatorSet that specifies the operator named by op_type.
     *
     * @generated from protobuf field: string domain = 7;
     */
    domain: string; // namespace Domain
    /**
     * Additional named attributes.
     *
     * @generated from protobuf field: repeated onnx.AttributeProto attribute = 5;
     */
    attribute: AttributeProto[];
    /**
     * A human-readable documentation for this node. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 6;
     */
    doc_string: string;
}
/**
 * Training information
 * TrainingInfoProto stores information for training a model.
 * In particular, this defines two functionalities: an initialization-step
 * and a training-algorithm-step. Initialization resets the model
 * back to its original state as if no training has been performed.
 * Training algorithm improves the model based on input data.
 *
 * The semantics of the initialization-step is that the initializers
 * in ModelProto.graph and in TrainingInfoProto.algorithm are first
 * initialized as specified by the initializers in the graph, and then
 * updated by the "initialization_binding" in every instance in
 * ModelProto.training_info.
 *
 * The field "algorithm" defines a computation graph which represents a
 * training algorithm's step. After the execution of a
 * TrainingInfoProto.algorithm, the initializers specified by "update_binding"
 * may be immediately updated. If the targeted training algorithm contains
 * consecutive update steps (such as block coordinate descent methods),
 * the user needs to create a TrainingInfoProto for each step.
 *
 * @generated from protobuf message onnx.TrainingInfoProto
 */
export interface TrainingInfoProto {
    /**
     * This field describes a graph to compute the initial tensors
     * upon starting the training process. Initialization graph has no input
     * and can have multiple outputs. Usually, trainable tensors in neural
     * networks are randomly initialized. To achieve that, for each tensor,
     * the user can put a random number operator such as RandomNormal or
     * RandomUniform in TrainingInfoProto.initialization.node and assign its
     * random output to the specific tensor using "initialization_binding".
     * This graph can also set the initializers in "algorithm" in the same
     * TrainingInfoProto; a use case is resetting the number of training
     * iteration to zero.
     *
     * By default, this field is an empty graph and its evaluation does not
     * produce any output. Thus, no initializer would be changed by default.
     *
     * @generated from protobuf field: onnx.GraphProto initialization = 1;
     */
    initialization?: GraphProto;
    /**
     * This field represents a training algorithm step. Given required inputs,
     * it computes outputs to update initializers in its own or inference graph's
     * initializer lists. In general, this field contains loss node, gradient node,
     * optimizer node, increment of iteration count.
     *
     * An execution of the training algorithm step is performed by executing the
     * graph obtained by combining the inference graph (namely "ModelProto.graph")
     * and the "algorithm" graph. That is, the actual
     * input/initializer/output/node/value_info/sparse_initializer list of
     * the training graph is the concatenation of
     * "ModelProto.graph.input/initializer/output/node/value_info/sparse_initializer"
     * and "algorithm.input/initializer/output/node/value_info/sparse_initializer"
     * in that order. This combined graph must satisfy the normal ONNX conditions.
     * Now, let's provide a visualization of graph combination for clarity.
     * Let the inference graph (i.e., "ModelProto.graph") be
     *    tensor_a, tensor_b -> MatMul -> tensor_c -> Sigmoid -> tensor_d
     * and the "algorithm" graph be
     *    tensor_d -> Add -> tensor_e
     * The combination process results
     *    tensor_a, tensor_b -> MatMul -> tensor_c -> Sigmoid -> tensor_d -> Add -> tensor_e
     *
     * Notice that an input of a node in the "algorithm" graph may reference the
     * output of a node in the inference graph (but not the other way round). Also, inference
     * node cannot reference inputs of "algorithm". With these restrictions, inference graph
     * can always be run independently without training information.
     *
     * By default, this field is an empty graph and its evaluation does not
     * produce any output. Evaluating the default training step never
     * update any initializers.
     *
     * @generated from protobuf field: onnx.GraphProto algorithm = 2;
     */
    algorithm?: GraphProto;
    /**
     * This field specifies the bindings from the outputs of "initialization" to
     * some initializers in "ModelProto.graph.initializer" and
     * the "algorithm.initializer" in the same TrainingInfoProto.
     * See "update_binding" below for details.
     *
     * By default, this field is empty and no initializer would be changed
     * by the execution of "initialization".
     *
     * @generated from protobuf field: repeated onnx.StringStringEntryProto initialization_binding = 3;
     */
    initialization_binding: StringStringEntryProto[];
    /**
     * Gradient-based training is usually an iterative procedure. In one gradient
     * descent iteration, we apply
     *
     * x = x - r * g
     *
     * where "x" is the optimized tensor, "r" stands for learning rate, and "g" is
     * gradient of "x" with respect to a chosen loss. To avoid adding assignments
     * into the training graph, we split the update equation into
     *
     * y = x - r * g
     * x = y
     *
     * The user needs to save "y = x - r * g" into TrainingInfoProto.algorithm. To
     * tell that "y" should be assigned to "x", the field "update_binding" may
     * contain a key-value pair of strings, "x" (key of StringStringEntryProto)
     * and "y" (value of StringStringEntryProto).
     * For a neural network with multiple trainable (mutable) tensors, there can
     * be multiple key-value pairs in "update_binding".
     *
     * The initializers appears as keys in "update_binding" are considered
     * mutable variables. This implies some behaviors
     * as described below.
     *
     *  1. We have only unique keys in all "update_binding"s so that two
     *     variables may not have the same name. This ensures that one
     *     variable is assigned up to once.
     *  2. The keys must appear in names of "ModelProto.graph.initializer" or
     *     "TrainingInfoProto.algorithm.initializer".
     *  3. The values must be output names of "algorithm" or "ModelProto.graph.output".
     *  4. Mutable variables are initialized to the value specified by the
     *     corresponding initializer, and then potentially updated by
     *     "initializer_binding"s and "update_binding"s in "TrainingInfoProto"s.
     *
     * This field usually contains names of trainable tensors
     * (in ModelProto.graph), optimizer states such as momentums in advanced
     * stochastic gradient methods (in TrainingInfoProto.graph),
     * and number of training iterations (in TrainingInfoProto.graph).
     *
     * By default, this field is empty and no initializer would be changed
     * by the execution of "algorithm".
     *
     * @generated from protobuf field: repeated onnx.StringStringEntryProto update_binding = 4;
     */
    update_binding: StringStringEntryProto[];
}
/**
 * Models
 *
 * ModelProto is a top-level file/container format for bundling a ML model and
 * associating its computation graph with metadata.
 *
 * The semantics of the model are described by the associated GraphProto's.
 *
 * @generated from protobuf message onnx.ModelProto
 */
export interface ModelProto {
    /**
     * The version of the IR this model targets. See Version enum above.
     * This field MUST be present.
     *
     * @generated from protobuf field: int64 ir_version = 1;
     */
    ir_version: number;
    /**
     * The OperatorSets this model relies on.
     * All ModelProtos MUST have at least one entry that
     * specifies which version of the ONNX OperatorSet is
     * being imported.
     *
     * All nodes in the ModelProto's graph will bind against the operator
     * with the same-domain/same-op_type operator with the HIGHEST version
     * in the referenced operator sets.
     *
     * @generated from protobuf field: repeated onnx.OperatorSetIdProto opset_import = 8;
     */
    opset_import: OperatorSetIdProto[];
    /**
     * The name of the framework or tool used to generate this model.
     * This field SHOULD be present to indicate which implementation/tool/framework
     * emitted the model.
     *
     * @generated from protobuf field: string producer_name = 2;
     */
    producer_name: string;
    /**
     * The version of the framework or tool used to generate this model.
     * This field SHOULD be present to indicate which implementation/tool/framework
     * emitted the model.
     *
     * @generated from protobuf field: string producer_version = 3;
     */
    producer_version: string;
    /**
     * Domain name of the model.
     * We use reverse domain names as name space indicators. For example:
     * `com.facebook.fair` or `com.microsoft.cognitiveservices`
     *
     * Together with `model_version` and GraphProto.name, this forms the unique identity of
     * the graph.
     *
     * @generated from protobuf field: string domain = 4;
     */
    domain: string;
    /**
     * The version of the graph encoded. See Version enum below.
     *
     * @generated from protobuf field: int64 model_version = 5;
     */
    model_version: number;
    /**
     * A human-readable documentation for this model. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 6;
     */
    doc_string: string;
    /**
     * The parameterized graph that is evaluated to execute the model.
     *
     * @generated from protobuf field: onnx.GraphProto graph = 7;
     */
    graph?: GraphProto;
    /**
     * Named metadata values; keys should be distinct.
     *
     * @generated from protobuf field: repeated onnx.StringStringEntryProto metadata_props = 14;
     */
    metadata_props: StringStringEntryProto[];
    /**
     * Training-specific information. Sequentially executing all stored
     * `TrainingInfoProto.algorithm`s and assigning their outputs following
     * the corresponding `TrainingInfoProto.update_binding`s is one training
     * iteration. Similarly, to initialize the model
     * (as if training hasn't happened), the user should sequentially execute
     * all stored `TrainingInfoProto.initialization`s and assigns their outputs
     * using `TrainingInfoProto.initialization_binding`s.
     *
     * If this field is empty, the training behavior of the model is undefined.
     *
     * @generated from protobuf field: repeated onnx.TrainingInfoProto training_info = 20;
     */
    training_info: TrainingInfoProto[];
    /**
     * A list of function protos local to the model.
     *
     * Name of the function "FunctionProto.name" should be unique within the domain "FunctionProto.domain".
     * In case of any conflicts the behavior (whether the model local functions are given higher priority,
     * or standard operator sets are given higher priotity or this is treated as error) is defined by
     * the runtimes.
     *
     * The operator sets imported by FunctionProto should be compatible with the ones
     * imported by ModelProto and other model local FunctionProtos.
     * Example, if same operator set say 'A' is imported by a FunctionProto and ModelProto
     * or by 2 FunctionProtos then versions for the operator set may be different but,
     * the operator schema returned for op_type, domain, version combination
     * for both the versions should be same for every node in the function body.
     *
     * One FunctionProto can reference other FunctionProto in the model, however, recursive reference
     * is not allowed.
     *
     * @generated from protobuf field: repeated onnx.FunctionProto functions = 25;
     */
    functions: FunctionProto[];
}
/**
 * StringStringEntryProto follows the pattern for cross-proto-version maps.
 * See https://developers.google.com/protocol-buffers/docs/proto3#maps
 *
 * @generated from protobuf message onnx.StringStringEntryProto
 */
export interface StringStringEntryProto {
    /**
     * @generated from protobuf field: string key = 1;
     */
    key: string;
    /**
     * @generated from protobuf field: string value = 2;
     */
    value: string;
}
/**
 * @generated from protobuf message onnx.TensorAnnotation
 */
export interface TensorAnnotation {
    /**
     * @generated from protobuf field: string tensor_name = 1;
     */
    tensor_name: string;
    /**
     * <key, value> pairs to annotate tensor specified by <tensor_name> above.
     * The keys used in the mapping below must be pre-defined in ONNX spec.
     * For example, for 8-bit linear quantization case, 'SCALE_TENSOR', 'ZERO_POINT_TENSOR' will be pre-defined as
     * quantization parameter keys.
     *
     * @generated from protobuf field: repeated onnx.StringStringEntryProto quant_parameter_tensor_names = 2;
     */
    quant_parameter_tensor_names: StringStringEntryProto[];
}
/**
 * Graphs
 *
 * A graph defines the computational logic of a model and is comprised of a parameterized
 * list of nodes that form a directed acyclic graph based on their inputs and outputs.
 * This is the equivalent of the "network" or "graph" in many deep learning
 * frameworks.
 *
 * @generated from protobuf message onnx.GraphProto
 */
export interface GraphProto {
    /**
     * The nodes in the graph, sorted topologically.
     *
     * @generated from protobuf field: repeated onnx.NodeProto node = 1;
     */
    node: NodeProto[];
    /**
     * The name of the graph.
     *
     * @generated from protobuf field: string name = 2;
     */
    name: string; // namespace Graph
    /**
     * A list of named tensor values, used to specify constant inputs of the graph.
     * Each initializer (both TensorProto as well SparseTensorProto) MUST have a name.
     * The name MUST be unique across both initializer and sparse_initializer,
     * but the name MAY also appear in the input list.
     *
     * @generated from protobuf field: repeated onnx.TensorProto initializer = 5;
     */
    initializer: TensorProto[];
    /**
     * Initializers (see above) stored in sparse format.
     *
     * @generated from protobuf field: repeated onnx.SparseTensorProto sparse_initializer = 15;
     */
    sparse_initializer: SparseTensorProto[];
    /**
     * A human-readable documentation for this graph. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 10;
     */
    doc_string: string;
    /**
     * The inputs and outputs of the graph.
     *
     * @generated from protobuf field: repeated onnx.ValueInfoProto input = 11;
     */
    input: ValueInfoProto[];
    /**
     * @generated from protobuf field: repeated onnx.ValueInfoProto output = 12;
     */
    output: ValueInfoProto[];
    /**
     * Information for the values in the graph. The ValueInfoProto.name's
     * must be distinct. It is optional for a value to appear in value_info list.
     *
     * @generated from protobuf field: repeated onnx.ValueInfoProto value_info = 13;
     */
    value_info: ValueInfoProto[];
    /**
     * This field carries information to indicate the mapping among a tensor and its
     * quantization parameter tensors. For example:
     * For tensor 'a', it may have {'SCALE_TENSOR', 'a_scale'} and {'ZERO_POINT_TENSOR', 'a_zero_point'} annotated,
     * which means, tensor 'a_scale' and tensor 'a_zero_point' are scale and zero point of tensor 'a' in the model.
     *
     * @generated from protobuf field: repeated onnx.TensorAnnotation quantization_annotation = 14;
     */
    quantization_annotation: TensorAnnotation[];
}
/**
 * Tensors
 *
 * A serialized tensor value.
 *
 * @generated from protobuf message onnx.TensorProto
 */
export interface TensorProto {
    /**
     * The shape of the tensor.
     *
     * @generated from protobuf field: repeated int64 dims = 1;
     */
    dims: number[];
    /**
     * The data type of the tensor.
     * This field MUST have a valid TensorProto.DataType value
     *
     * @generated from protobuf field: int32 data_type = 2;
     */
    data_type: number;
    /**
     * @generated from protobuf field: onnx.TensorProto.Segment segment = 3;
     */
    segment?: TensorProto_Segment;
    // Tensor content must be organized in row-major order.
    // 
    // Depending on the data_type field, exactly one of the fields below with
    // name ending in _data is used to store the elements of the tensor.

    /**
     * For float and complex64 values
     * Complex64 tensors are encoded as a single array of floats,
     * with the real components appearing in odd numbered positions,
     * and the corresponding imaginary component appearing in the
     * subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]
     * is encoded as [1.0, 2.0 ,3.0 ,4.0]
     * When this field is present, the data_type field MUST be FLOAT or COMPLEX64.
     *
     * @generated from protobuf field: repeated float float_data = 4 [packed = true];
     */
    float_data: number[];
    /**
     * For int32, uint8, int8, uint16, int16, bool, float8, and float16 values
     * float16 and float8 values must be bit-wise converted to an uint16_t prior
     * to writing to the buffer.
     * When this field is present, the data_type field MUST be
     * INT32, INT16, INT8, UINT16, UINT8, BOOL, FLOAT16, BFLOAT16, FLOAT8E4M3FN, FLOAT8E4M3FNUZ, FLOAT8E5M2, FLOAT8E5M2FNUZ
     *
     * @generated from protobuf field: repeated int32 int32_data = 5 [packed = true];
     */
    int32_data: number[];
    /**
     * For strings.
     * Each element of string_data is a UTF-8 encoded Unicode
     * string. No trailing null, no leading BOM. The protobuf "string"
     * scalar type is not used to match ML community conventions.
     * When this field is present, the data_type field MUST be STRING
     *
     * @generated from protobuf field: repeated bytes string_data = 6;
     */
    string_data: Uint8Array[];
    /**
     * For int64.
     * When this field is present, the data_type field MUST be INT64
     *
     * @generated from protobuf field: repeated int64 int64_data = 7 [packed = true];
     */
    int64_data: number[];
    /**
     * Optionally, a name for the tensor.
     *
     * @generated from protobuf field: string name = 8;
     */
    name: string; // namespace Value
    /**
     * A human-readable documentation for this tensor. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 12;
     */
    doc_string: string;
    /**
     * Serializations can either use one of the fields above, or use this
     * raw bytes field. The only exception is the string case, where one is
     * required to store the content in the repeated bytes string_data field.
     *
     * When this raw_data field is used to store tensor value, elements MUST
     * be stored in as fixed-width, little-endian order.
     * Floating-point data types MUST be stored in IEEE 754 format.
     * Complex64 elements must be written as two consecutive FLOAT values, real component first.
     * Complex128 elements must be written as two consecutive DOUBLE values, real component first.
     * Boolean type MUST be written one byte per tensor element (00000001 for true, 00000000 for false).
     *
     * Note: the advantage of specific field rather than the raw_data field is
     * that in some cases (e.g. int data), protobuf does a better packing via
     * variable length storage, and may lead to smaller binary footprint.
     * When this field is present, the data_type field MUST NOT be STRING or UNDEFINED
     *
     * @generated from protobuf field: bytes raw_data = 9;
     */
    raw_data: Uint8Array;
    /**
     * Data can be stored inside the protobuf file using type-specific fields or raw_data.
     * Alternatively, raw bytes data can be stored in an external file, using the external_data field.
     * external_data stores key-value pairs describing data location. Recognized keys are:
     * - "location" (required) - POSIX filesystem path relative to the directory where the ONNX
     *                           protobuf model was stored
     * - "offset" (optional) - position of byte at which stored data begins. Integer stored as string.
     *                         Offset values SHOULD be multiples 4096 (page size) to enable mmap support.
     * - "length" (optional) - number of bytes containing data. Integer stored as string.
     * - "checksum" (optional) - SHA1 digest of file specified in under 'location' key.
     *
     * @generated from protobuf field: repeated onnx.StringStringEntryProto external_data = 13;
     */
    external_data: StringStringEntryProto[];
    /**
     * If value not set, data is stored in raw_data (if set) otherwise in type-specified field.
     *
     * @generated from protobuf field: onnx.TensorProto.DataLocation data_location = 14;
     */
    data_location: TensorProto_DataLocation;
    /**
     * For double
     * Complex128 tensors are encoded as a single array of doubles,
     * with the real components appearing in odd numbered positions,
     * and the corresponding imaginary component appearing in the
     * subsequent even numbered position. (e.g., [1.0 + 2.0i, 3.0 + 4.0i]
     * is encoded as [1.0, 2.0 ,3.0 ,4.0]
     * When this field is present, the data_type field MUST be DOUBLE or COMPLEX128
     *
     * @generated from protobuf field: repeated double double_data = 10 [packed = true];
     */
    double_data: number[];
    /**
     * For uint64 and uint32 values
     * When this field is present, the data_type field MUST be
     * UINT32 or UINT64
     *
     * @generated from protobuf field: repeated uint64 uint64_data = 11 [packed = true];
     */
    uint64_data: number[];
}
/**
 * For very large tensors, we may want to store them in chunks, in which
 * case the following fields will specify the segment that is stored in
 * the current TensorProto.
 *
 * @generated from protobuf message onnx.TensorProto.Segment
 */
export interface TensorProto_Segment {
    /**
     * @generated from protobuf field: int64 begin = 1;
     */
    begin: number;
    /**
     * @generated from protobuf field: int64 end = 2;
     */
    end: number;
}
/**
 * @generated from protobuf enum onnx.TensorProto.DataType
 */
export enum TensorProto_DataType {
    /**
     * @generated from protobuf enum value: UNDEFINED = 0;
     */
    UNDEFINED = 0,
    /**
     * Basic types.
     *
     * float
     *
     * @generated from protobuf enum value: FLOAT = 1;
     */
    FLOAT = 1,
    /**
     * uint8_t
     *
     * @generated from protobuf enum value: UINT8 = 2;
     */
    UINT8 = 2,
    /**
     * int8_t
     *
     * @generated from protobuf enum value: INT8 = 3;
     */
    INT8 = 3,
    /**
     * uint16_t
     *
     * @generated from protobuf enum value: UINT16 = 4;
     */
    UINT16 = 4,
    /**
     * int16_t
     *
     * @generated from protobuf enum value: INT16 = 5;
     */
    INT16 = 5,
    /**
     * int32_t
     *
     * @generated from protobuf enum value: INT32 = 6;
     */
    INT32 = 6,
    /**
     * int64_t
     *
     * @generated from protobuf enum value: INT64 = 7;
     */
    INT64 = 7,
    /**
     * string
     *
     * @generated from protobuf enum value: STRING = 8;
     */
    STRING = 8,
    /**
     * bool
     *
     * @generated from protobuf enum value: BOOL = 9;
     */
    BOOL = 9,
    /**
     * IEEE754 half-precision floating-point format (16 bits wide).
     * This format has 1 sign bit, 5 exponent bits, and 10 mantissa bits.
     *
     * @generated from protobuf enum value: FLOAT16 = 10;
     */
    FLOAT16 = 10,
    /**
     * @generated from protobuf enum value: DOUBLE = 11;
     */
    DOUBLE = 11,
    /**
     * @generated from protobuf enum value: UINT32 = 12;
     */
    UINT32 = 12,
    /**
     * @generated from protobuf enum value: UINT64 = 13;
     */
    UINT64 = 13,
    /**
     * complex with float32 real and imaginary components
     *
     * @generated from protobuf enum value: COMPLEX64 = 14;
     */
    COMPLEX64 = 14,
    /**
     * complex with float64 real and imaginary components
     *
     * @generated from protobuf enum value: COMPLEX128 = 15;
     */
    COMPLEX128 = 15,
    /**
     * Non-IEEE floating-point format based on IEEE754 single-precision
     * floating-point number truncated to 16 bits.
     * This format has 1 sign bit, 8 exponent bits, and 7 mantissa bits.
     *
     * @generated from protobuf enum value: BFLOAT16 = 16;
     */
    BFLOAT16 = 16,
    /**
     * Non-IEEE floating-point format based on papers
     * FP8 Formats for Deep Learning, https://arxiv.org/abs/2209.05433,
     * 8-bit Numerical Formats For Deep Neural Networks, https://arxiv.org/pdf/2206.02915.pdf.
     * Operators supported FP8 are Cast, CastLike, QuantizeLinear, DequantizeLinear.
     * The computation usually happens inside a block quantize / dequantize
     * fused by the runtime.
     *
     * float 8, mostly used for coefficients, supports nan, not inf
     *
     * @generated from protobuf enum value: FLOAT8E4M3FN = 17;
     */
    FLOAT8E4M3FN = 17,
    /**
     * float 8, mostly used for coefficients, supports nan, not inf, no negative zero
     *
     * @generated from protobuf enum value: FLOAT8E4M3FNUZ = 18;
     */
    FLOAT8E4M3FNUZ = 18,
    /**
     * follows IEEE 754, supports nan, inf, mostly used for gradients
     *
     * @generated from protobuf enum value: FLOAT8E5M2 = 19;
     */
    FLOAT8E5M2 = 19,
    /**
     * follows IEEE 754, supports nan, inf, mostly used for gradients, no negative zero
     *
     * @generated from protobuf enum value: FLOAT8E5M2FNUZ = 20;
     */
    FLOAT8E5M2FNUZ = 20
}
/**
 * Location of the data for this tensor. MUST be one of:
 * - DEFAULT - data stored inside the protobuf message. Data is stored in raw_data (if set) otherwise in type-specified field.
 * - EXTERNAL - data stored in an external location as described by external_data field.
 *
 * @generated from protobuf enum onnx.TensorProto.DataLocation
 */
export enum TensorProto_DataLocation {
    /**
     * @generated from protobuf enum value: DEFAULT = 0;
     */
    DEFAULT = 0,
    /**
     * @generated from protobuf enum value: EXTERNAL = 1;
     */
    EXTERNAL = 1
}
/**
 * A serialized sparse-tensor value
 *
 * @generated from protobuf message onnx.SparseTensorProto
 */
export interface SparseTensorProto {
    /**
     * The sequence of non-default values are encoded as a tensor of shape [NNZ].
     * The default-value is zero for numeric tensors, and empty-string for string tensors.
     * values must have a non-empty name present which serves as a name for SparseTensorProto
     * when used in sparse_initializer list.
     *
     * @generated from protobuf field: onnx.TensorProto values = 1;
     */
    values?: TensorProto;
    /**
     * The indices of the non-default values, which may be stored in one of two formats.
     * (a) Indices can be a tensor of shape [NNZ, rank] with the [i,j]-th value
     * corresponding to the j-th index of the i-th value (in the values tensor).
     * (b) Indices can be a tensor of shape [NNZ], in which case the i-th value
     * must be the linearized-index of the i-th value (in the values tensor).
     * The linearized-index can be converted into an index tuple (k_1,...,k_rank)
     * using the shape provided below.
     * The indices must appear in ascending order without duplication.
     * In the first format, the ordering is lexicographic-ordering:
     * e.g., index-value [1,4] must appear before [2,1]
     *
     * @generated from protobuf field: onnx.TensorProto indices = 2;
     */
    indices?: TensorProto;
    /**
     * The shape of the underlying dense-tensor: [dim_1, dim_2, ... dim_rank]
     *
     * @generated from protobuf field: repeated int64 dims = 3;
     */
    dims: number[];
}
/**
 * Defines a tensor shape. A dimension can be either an integer value
 * or a symbolic variable. A symbolic variable represents an unknown
 * dimension.
 *
 * @generated from protobuf message onnx.TensorShapeProto
 */
export interface TensorShapeProto {
    /**
     * @generated from protobuf field: repeated onnx.TensorShapeProto.Dimension dim = 1;
     */
    dim: TensorShapeProto_Dimension[];
}
/**
 * @generated from protobuf message onnx.TensorShapeProto.Dimension
 */
export interface TensorShapeProto_Dimension {
    /**
     * @generated from protobuf oneof: value
     */
    value: {
        oneofKind: "dim_value";
        /**
         * @generated from protobuf field: int64 dim_value = 1;
         */
        dim_value: number;
    } | {
        oneofKind: "dim_param";
        /**
         * @generated from protobuf field: string dim_param = 2;
         */
        dim_param: string; // namespace Shape
    } | {
        oneofKind: undefined;
    };
    /**
     * Standard denotation can optionally be used to denote tensor
     * dimensions with standard semantic descriptions to ensure
     * that operations are applied to the correct axis of a tensor.
     * Refer to https://github.com/onnx/onnx/blob/main/docs/DimensionDenotation.md#denotation-definition
     * for pre-defined dimension denotations.
     *
     * @generated from protobuf field: string denotation = 3;
     */
    denotation: string;
}
/**
 * Types
 *
 * The standard ONNX data types.
 *
 * @generated from protobuf message onnx.TypeProto
 */
export interface TypeProto {
    /**
     * @generated from protobuf oneof: value
     */
    value: {
        oneofKind: "tensor_type";
        /**
         * The type of a tensor.
         *
         * @generated from protobuf field: onnx.TypeProto.Tensor tensor_type = 1;
         */
        tensor_type: TypeProto_Tensor;
    } | {
        oneofKind: "sequence_type";
        // NOTE:  DNN-only implementations of ONNX MAY elect to not support non-tensor values
        //        as input and output to graphs and nodes. These types are needed to naturally
        //        support classical ML operators.  DNN operators SHOULD restrict their input
        //        and output types to tensors.

        /**
         * The type of a sequence.
         *
         * @generated from protobuf field: onnx.TypeProto.Sequence sequence_type = 4;
         */
        sequence_type: TypeProto_Sequence;
    } | {
        oneofKind: "map_type";
        /**
         * The type of a map.
         *
         * @generated from protobuf field: onnx.TypeProto.Map map_type = 5;
         */
        map_type: TypeProto_Map;
    } | {
        oneofKind: "optional_type";
        /**
         * The type of an optional.
         *
         * @generated from protobuf field: onnx.TypeProto.Optional optional_type = 9;
         */
        optional_type: TypeProto_Optional;
    } | {
        oneofKind: "sparse_tensor_type";
        /**
         * Type of the sparse tensor
         *
         * @generated from protobuf field: onnx.TypeProto.SparseTensor sparse_tensor_type = 8;
         */
        sparse_tensor_type: TypeProto_SparseTensor;
    } | {
        oneofKind: undefined;
    };
    /**
     * An optional denotation can be used to denote the whole
     * type with a standard semantic description as to what is
     * stored inside. Refer to https://github.com/onnx/onnx/blob/main/docs/TypeDenotation.md#type-denotation-definition
     * for pre-defined type denotations.
     *
     * @generated from protobuf field: string denotation = 6;
     */
    denotation: string;
}
/**
 * @generated from protobuf message onnx.TypeProto.Tensor
 */
export interface TypeProto_Tensor {
    /**
     * This field MUST NOT have the value of UNDEFINED
     * This field MUST have a valid TensorProto.DataType value
     * This field MUST be present for this version of the IR.
     *
     * @generated from protobuf field: int32 elem_type = 1;
     */
    elem_type: number;
    /**
     * @generated from protobuf field: onnx.TensorShapeProto shape = 2;
     */
    shape?: TensorShapeProto;
}
/**
 * repeated T
 *
 * @generated from protobuf message onnx.TypeProto.Sequence
 */
export interface TypeProto_Sequence {
    /**
     * The type and optional shape of each element of the sequence.
     * This field MUST be present for this version of the IR.
     *
     * @generated from protobuf field: onnx.TypeProto elem_type = 1;
     */
    elem_type?: TypeProto;
}
/**
 * map<K,V>
 *
 * @generated from protobuf message onnx.TypeProto.Map
 */
export interface TypeProto_Map {
    /**
     * This field MUST have a valid TensorProto.DataType value
     * This field MUST be present for this version of the IR.
     * This field MUST refer to an integral type ([U]INT{8|16|32|64}) or STRING
     *
     * @generated from protobuf field: int32 key_type = 1;
     */
    key_type: number;
    /**
     * This field MUST be present for this version of the IR.
     *
     * @generated from protobuf field: onnx.TypeProto value_type = 2;
     */
    value_type?: TypeProto;
}
/**
 * wrapper for Tensor, Sequence, or Map
 *
 * @generated from protobuf message onnx.TypeProto.Optional
 */
export interface TypeProto_Optional {
    /**
     * The type and optional shape of the element wrapped.
     * This field MUST be present for this version of the IR.
     * Possible values correspond to OptionalProto.DataType enum
     *
     * @generated from protobuf field: onnx.TypeProto elem_type = 1;
     */
    elem_type?: TypeProto;
}
/**
 * @generated from protobuf message onnx.TypeProto.SparseTensor
 */
export interface TypeProto_SparseTensor {
    /**
     * This field MUST NOT have the value of UNDEFINED
     * This field MUST have a valid TensorProto.DataType value
     * This field MUST be present for this version of the IR.
     *
     * @generated from protobuf field: int32 elem_type = 1;
     */
    elem_type: number;
    /**
     * @generated from protobuf field: onnx.TensorShapeProto shape = 2;
     */
    shape?: TensorShapeProto;
}
/**
 * Operator Sets
 *
 * OperatorSets are uniquely identified by a (domain, opset_version) pair.
 *
 * @generated from protobuf message onnx.OperatorSetIdProto
 */
export interface OperatorSetIdProto {
    /**
     * The domain of the operator set being identified.
     * The empty string ("") or absence of this field implies the operator
     * set that is defined as part of the ONNX specification.
     * This field MUST be present in this version of the IR when referring to any other operator set.
     *
     * @generated from protobuf field: string domain = 1;
     */
    domain: string;
    /**
     * The version of the operator set being identified.
     * This field MUST be present in this version of the IR.
     *
     * @generated from protobuf field: int64 version = 2;
     */
    version: number;
}
/**
 * @generated from protobuf message onnx.FunctionProto
 */
export interface FunctionProto {
    /**
     * The name of the function, similar usage of op_type in OperatorProto.
     * Combined with FunctionProto.domain, this forms the unique identity of
     * the FunctionProto.
     *
     * @generated from protobuf field: string name = 1;
     */
    name: string;
    /**
     * The inputs and outputs of the function.
     *
     * @generated from protobuf field: repeated string input = 4;
     */
    input: string[];
    /**
     * @generated from protobuf field: repeated string output = 5;
     */
    output: string[];
    /**
     * The attribute parameters of the function.
     * It is for function parameters without default values.
     *
     * @generated from protobuf field: repeated string attribute = 6;
     */
    attribute: string[];
    /**
     * The attribute protos of the function.
     * It is for function attributes with default values.
     * A function attribute shall be represented either as
     * a string attribute or an AttributeProto, not both.
     *
     * @generated from protobuf field: repeated onnx.AttributeProto attribute_proto = 11;
     */
    attribute_proto: AttributeProto[];
    /**
     * The nodes in the function.
     *
     * @generated from protobuf field: repeated onnx.NodeProto node = 7;
     */
    node: NodeProto[];
    /**
     * A human-readable documentation for this function. Markdown is allowed.
     *
     * @generated from protobuf field: string doc_string = 8;
     */
    doc_string: string;
    // The OperatorSets this function body (graph) relies on.
    // 
    // All nodes in the function body (graph) will bind against the operator
    // with the same-domain/same-op_type operator with the HIGHEST version
    // in the referenced operator sets. This means at most one version can be relied
    // for one domain.
    // 
    // The operator sets imported by FunctionProto should be compatible with the ones
    // imported by ModelProto. Example, if same operator set say 'A' is imported by FunctionProto
    // and ModelProto then versions for the operator set may be different but,
    // the operator schema returned for op_type, domain, version combination
    // for both the versions should be same.

    /**
     * @generated from protobuf field: repeated onnx.OperatorSetIdProto opset_import = 9;
     */
    opset_import: OperatorSetIdProto[];
    /**
     * The domain which this function belongs to. Combined with FunctionProto.name, this forms the unique identity of
     * the FunctionProto.
     *
     * @generated from protobuf field: string domain = 10;
     */
    domain: string;
}
// Overview
// 
// ONNX is an open specification that is comprised of the following components:
// 
// 1)  A definition of an extensible computation graph model.
// 2)  Definitions of standard data types.
// 3)  Definitions of built-in operators.
// 
// This document describes the syntax of models and their computation graphs,
// as well as the standard data types. Together, they are referred to as the ONNX
// Intermediate Representation, or 'IR' for short.
// 
// The normative semantic specification of the ONNX IR is found in docs/IR.md.
// Definitions of the built-in neural network operators may be found in docs/Operators.md.

// Notes
// 
// Protobuf compatibility
// 
// To simplify framework compatibility, ONNX is defined using the subset of protobuf
// that is compatible with both protobuf v2 and v3. This means that we do not use any
// protobuf features that are only available in one of the two versions.
// 
// Here are the most notable contortions we have to carry out to work around
// these limitations:
// 
//   - No 'map' (added protobuf 3.0). We instead represent mappings as lists
//     of key-value pairs, where order does not matter and duplicates
//     are not allowed.

/**
 * Versioning
 *
 * ONNX versioning is specified in docs/IR.md and elaborated on in docs/Versioning.md
 *
 * To be compatible with both proto2 and proto3, we will use a version number
 * that is not defined by the default value but an explicit enum number.
 *
 * @generated from protobuf enum onnx.Version
 */
export enum Version {
    /**
     * proto3 requires the first enum value to be zero.
     * We add this just to appease the compiler.
     *
     * @generated from protobuf enum value: _START_VERSION = 0;
     */
    _START_VERSION = 0,
    /**
     * The version field is always serialized and we will use it to store the
     * version that the  graph is generated from. This helps us set up version
     * control.
     * For the IR, we are using simple numbers starting with 0x00000001,
     * which was the version we published on Oct 10, 2017.
     *
     * @generated from protobuf enum value: IR_VERSION_2017_10_10 = 1;
     */
    IR_VERSION_2017_10_10 = 1,
    /**
     * IR_VERSION 2 published on Oct 30, 2017
     * - Added type discriminator to AttributeProto to support proto3 users
     *
     * @generated from protobuf enum value: IR_VERSION_2017_10_30 = 2;
     */
    IR_VERSION_2017_10_30 = 2,
    /**
     * IR VERSION 3 published on Nov 3, 2017
     * - For operator versioning:
     *    - Added new message OperatorSetIdProto
     *    - Added opset_import in ModelProto
     * - For vendor extensions, added domain in NodeProto
     *
     * @generated from protobuf enum value: IR_VERSION_2017_11_3 = 3;
     */
    IR_VERSION_2017_11_3 = 3,
    /**
     * IR VERSION 4 published on Jan 22, 2019
     * - Relax constraint that initializers should be a subset of graph inputs
     * - Add type BFLOAT16
     *
     * @generated from protobuf enum value: IR_VERSION_2019_1_22 = 4;
     */
    IR_VERSION_2019_1_22 = 4,
    /**
     * IR VERSION 5 published on March 18, 2019
     * - Add message TensorAnnotation.
     * - Add quantization annotation in GraphProto to map tensor with its scale and zero point quantization parameters.
     *
     * @generated from protobuf enum value: IR_VERSION_2019_3_18 = 5;
     */
    IR_VERSION_2019_3_18 = 5,
    /**
     * IR VERSION 6 published on Sep 19, 2019
     * - Add support for sparse tensor constants stored in model.
     *   - Add message SparseTensorProto
     *   - Add sparse initializers
     *
     * @generated from protobuf enum value: IR_VERSION_2019_9_19 = 6;
     */
    IR_VERSION_2019_9_19 = 6,
    /**
     * IR VERSION 7 published on May 8, 2020
     * - Add support to allow function body graph to rely on multiple external opreator sets.
     * - Add a list to promote inference graph's initializers to global and
     *   mutable variables. Global variables are visible in all graphs of the
     *   stored models.
     * - Add message TrainingInfoProto to store initialization
     *   method and training algorithm. The execution of TrainingInfoProto
     *   can modify the values of mutable variables.
     * - Implicitly add inference graph into each TrainingInfoProto's algorithm.
     *
     * @generated from protobuf enum value: IR_VERSION_2020_5_8 = 7;
     */
    IR_VERSION_2020_5_8 = 7,
    /**
     * IR VERSION 8 published on July 30, 2021
     * Introduce TypeProto.SparseTensor
     * Introduce TypeProto.Optional
     * Added a list of FunctionProtos local to the model
     * Deprecated since_version and operator status from FunctionProto
     *
     * @generated from protobuf enum value: IR_VERSION_2021_7_30 = 8;
     */
    IR_VERSION_2021_7_30 = 8,
    /**
     * IR VERSION 9 published on May 5, 2023
     * Added AttributeProto to FunctionProto so that default attribute values can be set.
     * Added FLOAT8E4M3FN, FLOAT8E4M3FNUZ, FLOAT8E5M2, FLOAT8E5M2FNUZ.
     *
     * @generated from protobuf enum value: IR_VERSION = 9;
     */
    IR_VERSION = 9
}
/**
 * Operator/function status.
 *
 * @generated from protobuf enum onnx.OperatorStatus
 */
export enum OperatorStatus {
    /**
     * @generated from protobuf enum value: EXPERIMENTAL = 0;
     */
    EXPERIMENTAL = 0,
    /**
     * @generated from protobuf enum value: STABLE = 1;
     */
    STABLE = 1
}
// @generated message type with reflection information, may provide speed optimized methods
class AttributeProto$Type extends MessageType<AttributeProto> {
    constructor() {
        super("onnx.AttributeProto", [
            { no: 1, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 21, name: "ref_attr_name", kind: "scalar", localName: "ref_attr_name", T: 9 /*ScalarType.STRING*/ },
            { no: 13, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ },
            { no: 20, name: "type", kind: "enum", T: () => ["onnx.AttributeProto.AttributeType", AttributeProto_AttributeType] },
            { no: 2, name: "f", kind: "scalar", T: 2 /*ScalarType.FLOAT*/ },
            { no: 3, name: "i", kind: "scalar", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 4, name: "s", kind: "scalar", T: 12 /*ScalarType.BYTES*/ },
            { no: 5, name: "t", kind: "message", T: () => TensorProto },
            { no: 6, name: "g", kind: "message", T: () => GraphProto },
            { no: 22, name: "sparse_tensor", kind: "message", localName: "sparse_tensor", T: () => SparseTensorProto },
            { no: 14, name: "tp", kind: "message", T: () => TypeProto },
            { no: 7, name: "floats", kind: "scalar", repeat: 1 /*RepeatType.PACKED*/, T: 2 /*ScalarType.FLOAT*/ },
            { no: 8, name: "ints", kind: "scalar", repeat: 1 /*RepeatType.PACKED*/, T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 9, name: "strings", kind: "scalar", repeat: 2 /*RepeatType.UNPACKED*/, T: 12 /*ScalarType.BYTES*/ },
            { no: 10, name: "tensors", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => TensorProto },
            { no: 11, name: "graphs", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => GraphProto },
            { no: 23, name: "sparse_tensors", kind: "message", localName: "sparse_tensors", repeat: 1 /*RepeatType.PACKED*/, T: () => SparseTensorProto },
            { no: 15, name: "type_protos", kind: "message", localName: "type_protos", repeat: 1 /*RepeatType.PACKED*/, T: () => TypeProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.AttributeProto
 */
export const AttributeProto = new AttributeProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ValueInfoProto$Type extends MessageType<ValueInfoProto> {
    constructor() {
        super("onnx.ValueInfoProto", [
            { no: 1, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "type", kind: "message", T: () => TypeProto },
            { no: 3, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.ValueInfoProto
 */
export const ValueInfoProto = new ValueInfoProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class NodeProto$Type extends MessageType<NodeProto> {
    constructor() {
        super("onnx.NodeProto", [
            { no: 1, name: "input", kind: "scalar", repeat: 2 /*RepeatType.UNPACKED*/, T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "output", kind: "scalar", repeat: 2 /*RepeatType.UNPACKED*/, T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 4, name: "op_type", kind: "scalar", localName: "op_type", T: 9 /*ScalarType.STRING*/ },
            { no: 7, name: "domain", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 5, name: "attribute", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => AttributeProto },
            { no: 6, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.NodeProto
 */
export const NodeProto = new NodeProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TrainingInfoProto$Type extends MessageType<TrainingInfoProto> {
    constructor() {
        super("onnx.TrainingInfoProto", [
            { no: 1, name: "initialization", kind: "message", T: () => GraphProto },
            { no: 2, name: "algorithm", kind: "message", T: () => GraphProto },
            { no: 3, name: "initialization_binding", kind: "message", localName: "initialization_binding", repeat: 1 /*RepeatType.PACKED*/, T: () => StringStringEntryProto },
            { no: 4, name: "update_binding", kind: "message", localName: "update_binding", repeat: 1 /*RepeatType.PACKED*/, T: () => StringStringEntryProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TrainingInfoProto
 */
export const TrainingInfoProto = new TrainingInfoProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class ModelProto$Type extends MessageType<ModelProto> {
    constructor() {
        super("onnx.ModelProto", [
            { no: 1, name: "ir_version", kind: "scalar", localName: "ir_version", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 8, name: "opset_import", kind: "message", localName: "opset_import", repeat: 1 /*RepeatType.PACKED*/, T: () => OperatorSetIdProto },
            { no: 2, name: "producer_name", kind: "scalar", localName: "producer_name", T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: "producer_version", kind: "scalar", localName: "producer_version", T: 9 /*ScalarType.STRING*/ },
            { no: 4, name: "domain", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 5, name: "model_version", kind: "scalar", localName: "model_version", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 6, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ },
            { no: 7, name: "graph", kind: "message", T: () => GraphProto },
            { no: 14, name: "metadata_props", kind: "message", localName: "metadata_props", repeat: 1 /*RepeatType.PACKED*/, T: () => StringStringEntryProto },
            { no: 20, name: "training_info", kind: "message", localName: "training_info", repeat: 1 /*RepeatType.PACKED*/, T: () => TrainingInfoProto },
            { no: 25, name: "functions", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => FunctionProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.ModelProto
 */
export const ModelProto = new ModelProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class StringStringEntryProto$Type extends MessageType<StringStringEntryProto> {
    constructor() {
        super("onnx.StringStringEntryProto", [
            { no: 1, name: "key", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "value", kind: "scalar", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.StringStringEntryProto
 */
export const StringStringEntryProto = new StringStringEntryProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TensorAnnotation$Type extends MessageType<TensorAnnotation> {
    constructor() {
        super("onnx.TensorAnnotation", [
            { no: 1, name: "tensor_name", kind: "scalar", localName: "tensor_name", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "quant_parameter_tensor_names", kind: "message", localName: "quant_parameter_tensor_names", repeat: 1 /*RepeatType.PACKED*/, T: () => StringStringEntryProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TensorAnnotation
 */
export const TensorAnnotation = new TensorAnnotation$Type();
// @generated message type with reflection information, may provide speed optimized methods
class GraphProto$Type extends MessageType<GraphProto> {
    constructor() {
        super("onnx.GraphProto", [
            { no: 1, name: "node", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => NodeProto },
            { no: 2, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 5, name: "initializer", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => TensorProto },
            { no: 15, name: "sparse_initializer", kind: "message", localName: "sparse_initializer", repeat: 1 /*RepeatType.PACKED*/, T: () => SparseTensorProto },
            { no: 10, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ },
            { no: 11, name: "input", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => ValueInfoProto },
            { no: 12, name: "output", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => ValueInfoProto },
            { no: 13, name: "value_info", kind: "message", localName: "value_info", repeat: 1 /*RepeatType.PACKED*/, T: () => ValueInfoProto },
            { no: 14, name: "quantization_annotation", kind: "message", localName: "quantization_annotation", repeat: 1 /*RepeatType.PACKED*/, T: () => TensorAnnotation }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.GraphProto
 */
export const GraphProto = new GraphProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TensorProto$Type extends MessageType<TensorProto> {
    constructor() {
        super("onnx.TensorProto", [
            { no: 1, name: "dims", kind: "scalar", repeat: 1 /*RepeatType.PACKED*/, T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 2, name: "data_type", kind: "scalar", localName: "data_type", T: 5 /*ScalarType.INT32*/ },
            { no: 3, name: "segment", kind: "message", T: () => TensorProto_Segment },
            { no: 4, name: "float_data", kind: "scalar", localName: "float_data", repeat: 1 /*RepeatType.PACKED*/, T: 2 /*ScalarType.FLOAT*/ },
            { no: 5, name: "int32_data", kind: "scalar", localName: "int32_data", repeat: 1 /*RepeatType.PACKED*/, T: 5 /*ScalarType.INT32*/ },
            { no: 6, name: "string_data", kind: "scalar", localName: "string_data", repeat: 2 /*RepeatType.UNPACKED*/, T: 12 /*ScalarType.BYTES*/ },
            { no: 7, name: "int64_data", kind: "scalar", localName: "int64_data", repeat: 1 /*RepeatType.PACKED*/, T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 8, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 12, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ },
            { no: 9, name: "raw_data", kind: "scalar", localName: "raw_data", T: 12 /*ScalarType.BYTES*/ },
            { no: 13, name: "external_data", kind: "message", localName: "external_data", repeat: 1 /*RepeatType.PACKED*/, T: () => StringStringEntryProto },
            { no: 14, name: "data_location", kind: "enum", localName: "data_location", T: () => ["onnx.TensorProto.DataLocation", TensorProto_DataLocation] },
            { no: 10, name: "double_data", kind: "scalar", localName: "double_data", repeat: 1 /*RepeatType.PACKED*/, T: 1 /*ScalarType.DOUBLE*/ },
            { no: 11, name: "uint64_data", kind: "scalar", localName: "uint64_data", repeat: 1 /*RepeatType.PACKED*/, T: 4 /*ScalarType.UINT64*/, L: 2 /*LongType.NUMBER*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TensorProto
 */
export const TensorProto = new TensorProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TensorProto_Segment$Type extends MessageType<TensorProto_Segment> {
    constructor() {
        super("onnx.TensorProto.Segment", [
            { no: 1, name: "begin", kind: "scalar", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 2, name: "end", kind: "scalar", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TensorProto.Segment
 */
export const TensorProto_Segment = new TensorProto_Segment$Type();
// @generated message type with reflection information, may provide speed optimized methods
class SparseTensorProto$Type extends MessageType<SparseTensorProto> {
    constructor() {
        super("onnx.SparseTensorProto", [
            { no: 1, name: "values", kind: "message", T: () => TensorProto },
            { no: 2, name: "indices", kind: "message", T: () => TensorProto },
            { no: 3, name: "dims", kind: "scalar", repeat: 1 /*RepeatType.PACKED*/, T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.SparseTensorProto
 */
export const SparseTensorProto = new SparseTensorProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TensorShapeProto$Type extends MessageType<TensorShapeProto> {
    constructor() {
        super("onnx.TensorShapeProto", [
            { no: 1, name: "dim", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => TensorShapeProto_Dimension }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TensorShapeProto
 */
export const TensorShapeProto = new TensorShapeProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TensorShapeProto_Dimension$Type extends MessageType<TensorShapeProto_Dimension> {
    constructor() {
        super("onnx.TensorShapeProto.Dimension", [
            { no: 1, name: "dim_value", kind: "scalar", localName: "dim_value", oneof: "value", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ },
            { no: 2, name: "dim_param", kind: "scalar", localName: "dim_param", oneof: "value", T: 9 /*ScalarType.STRING*/ },
            { no: 3, name: "denotation", kind: "scalar", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TensorShapeProto.Dimension
 */
export const TensorShapeProto_Dimension = new TensorShapeProto_Dimension$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TypeProto$Type extends MessageType<TypeProto> {
    constructor() {
        super("onnx.TypeProto", [
            { no: 1, name: "tensor_type", kind: "message", localName: "tensor_type", oneof: "value", T: () => TypeProto_Tensor },
            { no: 4, name: "sequence_type", kind: "message", localName: "sequence_type", oneof: "value", T: () => TypeProto_Sequence },
            { no: 5, name: "map_type", kind: "message", localName: "map_type", oneof: "value", T: () => TypeProto_Map },
            { no: 9, name: "optional_type", kind: "message", localName: "optional_type", oneof: "value", T: () => TypeProto_Optional },
            { no: 8, name: "sparse_tensor_type", kind: "message", localName: "sparse_tensor_type", oneof: "value", T: () => TypeProto_SparseTensor },
            { no: 6, name: "denotation", kind: "scalar", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TypeProto
 */
export const TypeProto = new TypeProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TypeProto_Tensor$Type extends MessageType<TypeProto_Tensor> {
    constructor() {
        super("onnx.TypeProto.Tensor", [
            { no: 1, name: "elem_type", kind: "scalar", localName: "elem_type", T: 5 /*ScalarType.INT32*/ },
            { no: 2, name: "shape", kind: "message", T: () => TensorShapeProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TypeProto.Tensor
 */
export const TypeProto_Tensor = new TypeProto_Tensor$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TypeProto_Sequence$Type extends MessageType<TypeProto_Sequence> {
    constructor() {
        super("onnx.TypeProto.Sequence", [
            { no: 1, name: "elem_type", kind: "message", localName: "elem_type", T: () => TypeProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TypeProto.Sequence
 */
export const TypeProto_Sequence = new TypeProto_Sequence$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TypeProto_Map$Type extends MessageType<TypeProto_Map> {
    constructor() {
        super("onnx.TypeProto.Map", [
            { no: 1, name: "key_type", kind: "scalar", localName: "key_type", T: 5 /*ScalarType.INT32*/ },
            { no: 2, name: "value_type", kind: "message", localName: "value_type", T: () => TypeProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TypeProto.Map
 */
export const TypeProto_Map = new TypeProto_Map$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TypeProto_Optional$Type extends MessageType<TypeProto_Optional> {
    constructor() {
        super("onnx.TypeProto.Optional", [
            { no: 1, name: "elem_type", kind: "message", localName: "elem_type", T: () => TypeProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TypeProto.Optional
 */
export const TypeProto_Optional = new TypeProto_Optional$Type();
// @generated message type with reflection information, may provide speed optimized methods
class TypeProto_SparseTensor$Type extends MessageType<TypeProto_SparseTensor> {
    constructor() {
        super("onnx.TypeProto.SparseTensor", [
            { no: 1, name: "elem_type", kind: "scalar", localName: "elem_type", T: 5 /*ScalarType.INT32*/ },
            { no: 2, name: "shape", kind: "message", T: () => TensorShapeProto }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.TypeProto.SparseTensor
 */
export const TypeProto_SparseTensor = new TypeProto_SparseTensor$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OperatorSetIdProto$Type extends MessageType<OperatorSetIdProto> {
    constructor() {
        super("onnx.OperatorSetIdProto", [
            { no: 1, name: "domain", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "version", kind: "scalar", T: 3 /*ScalarType.INT64*/, L: 2 /*LongType.NUMBER*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.OperatorSetIdProto
 */
export const OperatorSetIdProto = new OperatorSetIdProto$Type();
// @generated message type with reflection information, may provide speed optimized methods
class FunctionProto$Type extends MessageType<FunctionProto> {
    constructor() {
        super("onnx.FunctionProto", [
            { no: 1, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 4, name: "input", kind: "scalar", repeat: 2 /*RepeatType.UNPACKED*/, T: 9 /*ScalarType.STRING*/ },
            { no: 5, name: "output", kind: "scalar", repeat: 2 /*RepeatType.UNPACKED*/, T: 9 /*ScalarType.STRING*/ },
            { no: 6, name: "attribute", kind: "scalar", repeat: 2 /*RepeatType.UNPACKED*/, T: 9 /*ScalarType.STRING*/ },
            { no: 11, name: "attribute_proto", kind: "message", localName: "attribute_proto", repeat: 1 /*RepeatType.PACKED*/, T: () => AttributeProto },
            { no: 7, name: "node", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => NodeProto },
            { no: 8, name: "doc_string", kind: "scalar", localName: "doc_string", T: 9 /*ScalarType.STRING*/ },
            { no: 9, name: "opset_import", kind: "message", localName: "opset_import", repeat: 1 /*RepeatType.PACKED*/, T: () => OperatorSetIdProto },
            { no: 10, name: "domain", kind: "scalar", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
}
/**
 * @generated MessageType for protobuf message onnx.FunctionProto
 */
export const FunctionProto = new FunctionProto$Type();
